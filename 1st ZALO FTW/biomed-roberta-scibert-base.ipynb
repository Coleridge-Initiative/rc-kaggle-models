{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-special",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.034537,
     "end_time": "2021-06-24T12:41:18.072923",
     "exception": false,
     "start_time": "2021-06-24T12:41:18.038386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dirty-barrier",
   "metadata": {
    "papermill": {
     "duration": 0.031564,
     "end_time": "2021-06-24T12:41:18.135991",
     "exception": false,
     "start_time": "2021-06-24T12:41:18.104427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**TRAINING CONFIGS**\n",
    "\n",
    "* Training max sequence length: 320\n",
    "* Inference max sequence length: 320\n",
    "* Preprocessing win_size: 200 (words)\n",
    "* Batch size: 4\n",
    "* Head: Arcface (0.5, 10.0, easy_margin=True, centers=1)\n",
    "* Training SupportSet K: 3\n",
    "* Cased\n",
    "* Balanced Training Group Sampling\n",
    "* None Overlap Support Group Sampling\n",
    "* Support/Query groups are all unique groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-wedding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:18.203646Z",
     "iopub.status.busy": "2021-06-24T12:41:18.202888Z",
     "iopub.status.idle": "2021-06-24T12:41:18.207053Z",
     "shell.execute_reply": "2021-06-24T12:41:18.206469Z",
     "shell.execute_reply.started": "2021-06-24T12:36:36.637676Z"
    },
    "papermill": {
     "duration": 0.039257,
     "end_time": "2021-06-24T12:41:18.207175",
     "exception": false,
     "start_time": "2021-06-24T12:41:18.167918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WIN_SIZE = 200\n",
    "SEQUENCE_LENGTH = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manual-modeling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:18.273693Z",
     "iopub.status.busy": "2021-06-24T12:41:18.273224Z",
     "iopub.status.idle": "2021-06-24T12:41:18.284586Z",
     "shell.execute_reply": "2021-06-24T12:41:18.284180Z",
     "shell.execute_reply.started": "2021-06-24T12:36:38.413858Z"
    },
    "papermill": {
     "duration": 0.046256,
     "end_time": "2021-06-24T12:41:18.284683",
     "exception": false,
     "start_time": "2021-06-24T12:41:18.238427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pretrainedrobertabase/config.json\n",
      "/kaggle/input/pretrainedrobertabase/merges.txt\n",
      "/kaggle/input/pretrainedrobertabase/vocab.json\n",
      "/kaggle/input/pretrainedrobertabase/tf_model.h5\n",
      "/kaggle/input/pretrainedrobertabase/tokenizer_config.json\n",
      "/kaggle/input/pretrainedrobertabase/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/pretrainedrobertabase'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metric-victim",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:18.355538Z",
     "iopub.status.busy": "2021-06-24T12:41:18.354846Z",
     "iopub.status.idle": "2021-06-24T12:41:27.238284Z",
     "shell.execute_reply": "2021-06-24T12:41:27.238672Z",
     "shell.execute_reply.started": "2021-06-24T12:36:38.538514Z"
    },
    "papermill": {
     "duration": 8.922339,
     "end_time": "2021-06-24T12:41:27.238855",
     "exception": false,
     "start_time": "2021-06-24T12:41:18.316516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for i in range(len(physical_devices)):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[i], True)\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import *\n",
    "import re\n",
    "from collections import Counter\n",
    "import glob\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honey-carpet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.311353Z",
     "iopub.status.busy": "2021-06-24T12:41:27.309554Z",
     "iopub.status.idle": "2021-06-24T12:41:27.311977Z",
     "shell.execute_reply": "2021-06-24T12:41:27.312368Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.103868Z"
    },
    "papermill": {
     "duration": 0.040799,
     "end_time": "2021-06-24T12:41:27.312488",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.271689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_s_e_window_sliding(sample_len, win_size, step_size):\n",
    "    start = 0\n",
    "    end = win_size\n",
    "    s_e = []\n",
    "    s_e.append([start, end])\n",
    "    while end < sample_len:\n",
    "        start += step_size\n",
    "        end = start + win_size\n",
    "        s_e.append([start, end])\n",
    "\n",
    "    s_e[-1][0] -= s_e[-1][1] - sample_len\n",
    "    s_e[-1][0] = max(s_e[-1][0], 0)\n",
    "    s_e[-1][1] = sample_len\n",
    "    return s_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "through-privacy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.383481Z",
     "iopub.status.busy": "2021-06-24T12:41:27.382972Z",
     "iopub.status.idle": "2021-06-24T12:41:27.491655Z",
     "shell.execute_reply": "2021-06-24T12:41:27.490639Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.111850Z"
    },
    "papermill": {
     "duration": 0.146767,
     "end_time": "2021-06-24T12:41:27.491828",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.345061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/coleridgeinitiative-show-us-the-data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-detail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.566706Z",
     "iopub.status.busy": "2021-06-24T12:41:27.565576Z",
     "iopub.status.idle": "2021-06-24T12:41:27.568399Z",
     "shell.execute_reply": "2021-06-24T12:41:27.568004Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.236254Z"
    },
    "papermill": {
     "duration": 0.04406,
     "end_time": "2021-06-24T12:41:27.568505",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.524445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_label = train_df.cleaned_label.tolist()\n",
    "dataset_label = train_df.cleaned_label.tolist()\n",
    "dataset_title = train_df.dataset_title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chubby-championship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.639369Z",
     "iopub.status.busy": "2021-06-24T12:41:27.638611Z",
     "iopub.status.idle": "2021-06-24T12:41:27.646421Z",
     "shell.execute_reply": "2021-06-24T12:41:27.646034Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.251232Z"
    },
    "papermill": {
     "duration": 0.045413,
     "end_time": "2021-06-24T12:41:27.646525",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.601112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_1 = [x.lower().strip() for x in train_df['dataset_label'].unique()]\n",
    "temp_2 = [x.lower().strip() for x in train_df['dataset_title'].unique()]\n",
    "temp_3 = [x.lower().strip() for x in train_df['cleaned_label'].unique()]\n",
    "all_train_labels = list(set(temp_1 + temp_2 + temp_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-corner",
   "metadata": {
    "papermill": {
     "duration": 0.033175,
     "end_time": "2021-06-24T12:41:27.712053",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.678878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "square-province",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.780526Z",
     "iopub.status.busy": "2021-06-24T12:41:27.780048Z",
     "iopub.status.idle": "2021-06-24T12:41:27.788896Z",
     "shell.execute_reply": "2021-06-24T12:41:27.788361Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.268973Z"
    },
    "papermill": {
     "duration": 0.04432,
     "end_time": "2021-06-24T12:41:27.789004",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.744684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_IDS = glob.glob(\"/kaggle/input/coleridgeinitiative-show-us-the-data/test/**\")\n",
    "TEST_IDS = [TEST_ID.split(\"/\")[-1].split(\".\")[0] for TEST_ID in TEST_IDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "criminal-internship",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:27.867986Z",
     "iopub.status.busy": "2021-06-24T12:41:27.867369Z",
     "iopub.status.idle": "2021-06-24T12:41:27.992541Z",
     "shell.execute_reply": "2021-06-24T12:41:27.992129Z",
     "shell.execute_reply.started": "2021-06-24T12:36:47.283332Z"
    },
    "papermill": {
     "duration": 0.171097,
     "end_time": "2021-06-24T12:41:27.992662",
     "exception": false,
     "start_time": "2021-06-24T12:41:27.821565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Preprocessing TestSet]:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "[Preprocessing TestSet]: 100%|██████████| 4/4 [00:00<00:00, 614.08it/s]\n",
      "4it [00:00, 84.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 29799.67it/s]\n"
     ]
    }
   ],
   "source": [
    "win_size = WIN_SIZE\n",
    "\n",
    "def process(i):\n",
    "    ids = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "    pub_titles = []\n",
    "    cleaned_labels = []\n",
    "    x = json.load(open(\n",
    "        f\"/kaggle/input/coleridgeinitiative-show-us-the-data/test/{TEST_IDS[i]}.json\",\"rt\"))\n",
    "    label = \"unknow\"\n",
    "    full_text = \"\"\n",
    "    unique_id = []\n",
    "    for section in x:\n",
    "        raw_text = section[\"text\"].replace(\"\\n\", \" \")\n",
    "#         raw_text_encode = tokenizer.encode(raw_text)[1:-1]\n",
    "        raw_text_encode = raw_text.split()\n",
    "        s_e = generate_s_e_window_sliding(len(raw_text_encode), win_size, int(0.75*win_size))\n",
    "        for (s, e) in s_e:\n",
    "#             sent = tokenizer.decode(raw_text_encode[s:e]).strip()\n",
    "            sent = \" \".join(raw_text_encode[s:e]).strip()\n",
    "            texts.append(sent)\n",
    "            ids.append(TEST_IDS[i])\n",
    "            labels.append(label)\n",
    "        full_text += section[\"text\"].replace(\"\\n\", \" \") + \" \"\n",
    "    \n",
    "    unique_id = TEST_IDS[i]\n",
    "    full_text = full_text.strip()\n",
    "\n",
    "    results = {}\n",
    "    results[\"id\"] = ids\n",
    "    results[\"text\"] = texts\n",
    "    results[\"label\"] = labels\n",
    "    results[\"unique_id\"] = unique_id\n",
    "    results[\"full_text\"] = full_text\n",
    "    return results\n",
    "        \n",
    "# define map iterator\n",
    "def iterator_data(items_list):\n",
    "    for item in items_list:\n",
    "        yield item\n",
    "\n",
    "iterator_data = iterator_data(range(len(TEST_IDS)))\n",
    "p = Pool(8)\n",
    "\n",
    "partial_fn = partial(process)\n",
    "train_map = p.imap(\n",
    "    partial_fn,\n",
    "    tqdm(iterator_data, total=len(TEST_IDS), desc=\"[Preprocessing TestSet]\"),\n",
    "    chunksize=10,\n",
    ")\n",
    "\n",
    "results = []\n",
    "for result in tqdm(train_map):\n",
    "    results.append(result)\n",
    "\n",
    "ids = []\n",
    "texts = []\n",
    "labels = []\n",
    "unique_ids = []\n",
    "full_texts = []\n",
    "for result in tqdm(results):\n",
    "    ids.extend(result[\"id\"])\n",
    "    texts.extend(result[\"text\"])\n",
    "    labels.extend(result[\"label\"])\n",
    "    unique_ids.append(result[\"unique_id\"])\n",
    "    full_texts.append(result[\"full_text\"])\n",
    "    \n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"id\"] = ids\n",
    "test_df[\"text\"] = texts\n",
    "test_df[\"label\"] = labels\n",
    "test_df[\"group\"] = [-1] * len(ids)\n",
    "test_df[\"title\"] = [\"\"] * len(ids)\n",
    "\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-warner",
   "metadata": {
    "papermill": {
     "duration": 0.039605,
     "end_time": "2021-06-24T12:41:28.087966",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.048361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opposed-equipment",
   "metadata": {
    "papermill": {
     "duration": 0.034823,
     "end_time": "2021-06-24T12:41:28.157498",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.122675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coordinate-carrier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.250575Z",
     "iopub.status.busy": "2021-06-24T12:41:28.249639Z",
     "iopub.status.idle": "2021-06-24T12:41:28.252817Z",
     "shell.execute_reply": "2021-06-24T12:41:28.252354Z",
     "shell.execute_reply.started": "2021-06-24T12:36:55.360490Z"
    },
    "papermill": {
     "duration": 0.060653,
     "end_time": "2021-06-24T12:41:28.252960",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.192307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizerFast\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import math\n",
    "\n",
    "\n",
    "class QueryDataLoader(Sequence):\n",
    "    def __init__(self, data, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data.fillna(\"\")\n",
    "        self.batch_ids = self.data[\"id\"].tolist()\n",
    "        self.batch_text = self.data[\"text\"].tolist()\n",
    "        self.batch_label = self.data[\"label\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.batch_text) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.batch_ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        text = self.batch_text[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        label = self.batch_label[\n",
    "            index * self.batch_size : (index + 1) * self.batch_size\n",
    "        ]\n",
    "        classes = [1 if l != \"\" else 0 for l in label]\n",
    "        return id, text, label, classes\n",
    "\n",
    "\n",
    "class SupportQueryDataLoader(Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        tokenizer,\n",
    "        training_steps=500,\n",
    "        batch_size=32,\n",
    "        is_train=False,\n",
    "        query_dataloader=None,\n",
    "        query_masked=False,\n",
    "        return_query_ids=False,\n",
    "        return_query_labels=False,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data.fillna(\"\")\n",
    "        self.is_train = is_train\n",
    "        self.len = training_steps\n",
    "        self.query_dataloader = query_dataloader\n",
    "        self.query_masked = query_masked\n",
    "        self.return_query_ids = return_query_ids\n",
    "        self.return_query_labels = return_query_labels\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _create_group_data(self):\n",
    "        all_unique_group = list(self.data.group.unique())\n",
    "        for group in all_unique_group:\n",
    "            self.data_group[group] = list(\n",
    "                zip(\n",
    "                    list(self.data[self.data[\"group\"] == group].title),\n",
    "                    list(self.data[self.data[\"group\"] == group].text),\n",
    "                    list(self.data[self.data[\"group\"] == group].label),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.all_unique_group = all_unique_group\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_train:\n",
    "            for k in list(self.data_group.keys()):\n",
    "                self.data_group[k] = shuffle(self.data_group[k])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: create support/group data samples\n",
    "        support_samples = []\n",
    "        support_labels = []\n",
    "        support_classes = []\n",
    "        query_samples = []\n",
    "        query_labels = []\n",
    "        query_classes = []\n",
    "        (\n",
    "            query_ids,\n",
    "            query_samples,\n",
    "            query_labels,\n",
    "            query_classes,\n",
    "        ) = self.query_dataloader.__getitem__(index)\n",
    "        if self.return_query_ids is False:\n",
    "            query_ids = None\n",
    "\n",
    "        # step 3: tokenize and return compute sequence label\n",
    "        query_batch = {}\n",
    "        query_batch[\"input_ids\"] = []\n",
    "        query_batch[\"attention_mask\"] = []\n",
    "        query_batch[\"token_type_ids\"] = []\n",
    "        query_batch[\"ids\"] = []\n",
    "\n",
    "        for i in range(len(query_samples)):\n",
    "            out = self._process_data(\n",
    "                query_samples[i], query_labels[i], self.query_masked\n",
    "            )\n",
    "            query_batch[\"input_ids\"].append(out[\"input_ids\"])\n",
    "            query_batch[\"attention_mask\"].append(out[\"attention_mask\"])\n",
    "            query_batch[\"token_type_ids\"].append(out[\"token_type_ids\"])\n",
    "            if query_ids is not None:\n",
    "                query_batch[\"ids\"].append(query_ids[i])\n",
    "\n",
    "        # step 4: padding to max len\n",
    "        query_batch[\"input_ids\"] = pad_sequences(\n",
    "            query_batch[\"input_ids\"],\n",
    "            padding=\"post\",\n",
    "            value=self.tokenizer.pad_token_id,\n",
    "        )\n",
    "        for k in [\"attention_mask\", \"token_type_ids\"]:\n",
    "            pad_value = 0\n",
    "            query_batch[k] = pad_sequences(\n",
    "                query_batch[k], padding=\"post\", value=pad_value\n",
    "            )\n",
    "        \n",
    "        for k in list([\"input_ids\", \"attention_mask\", \"token_type_ids\"]):\n",
    "            query_batch[k] = np.array(query_batch[k]).astype(np.int32)\n",
    "\n",
    "        return query_batch\n",
    "\n",
    "    def _process_data(self, inp_string, label_string, masked_label=False):\n",
    "        input_tokenize = self.tokenizer(\n",
    "            inp_string, return_offsets_mapping=True, max_length=SEQUENCE_LENGTH, truncation=True\n",
    "        )\n",
    "        results = {\n",
    "            \"input_ids\": input_tokenize[\"input_ids\"],\n",
    "            \"attention_mask\": input_tokenize[\"attention_mask\"],\n",
    "            \"token_type_ids\": [0] * len(input_tokenize[\"input_ids\"]),\n",
    "        }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-capitol",
   "metadata": {
    "papermill": {
     "duration": 0.034278,
     "end_time": "2021-06-24T12:41:28.321628",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.287350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**MODELING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enclosed-fever",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.395433Z",
     "iopub.status.busy": "2021-06-24T12:41:28.394733Z",
     "iopub.status.idle": "2021-06-24T12:41:28.397213Z",
     "shell.execute_reply": "2021-06-24T12:41:28.397722Z",
     "shell.execute_reply.started": "2021-06-24T12:36:55.606012Z"
    },
    "papermill": {
     "duration": 0.041774,
     "end_time": "2021-06-24T12:41:28.397859",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.356085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def del_everything(model):\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "    del sess\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    del graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "better-brunei",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.481346Z",
     "iopub.status.busy": "2021-06-24T12:41:28.480678Z",
     "iopub.status.idle": "2021-06-24T12:41:28.601660Z",
     "shell.execute_reply": "2021-06-24T12:41:28.601191Z",
     "shell.execute_reply.started": "2021-06-24T12:36:55.758539Z"
    },
    "papermill": {
     "duration": 0.169642,
     "end_time": "2021-06-24T12:41:28.601787",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.432145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers.optimization_tf import WarmUp, AdamWeightDecay\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "\n",
    "\n",
    "class MetricLearningModel(tf.keras.Model):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.main_model = None\n",
    "        self.support_dense = tf.keras.layers.Dense(units=768, activation=None)\n",
    "        self.config = config\n",
    "        self.K = 3\n",
    "\n",
    "    def _compute_avg_embeddings(self, sequence_embeddings, attentions_mask, K=3):\n",
    "        embeddings = tf.reduce_mean(\n",
    "            attentions_mask * sequence_embeddings, axis=1\n",
    "        )  # [B * K, F]\n",
    "        if K > 1:\n",
    "            embeddings = tf.reshape(\n",
    "                embeddings,\n",
    "                (-1, K, self.support_dense.units),\n",
    "            )\n",
    "            embeddings = tf.reduce_mean(embeddings, axis=1)  # [B, F]\n",
    "        return embeddings\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        inputs,\n",
    "        training=False,\n",
    "        sequence_labels=None,\n",
    "        mask_embeddings=None,\n",
    "        nomask_embeddings=None,\n",
    "        use_only_mask=False\n",
    "    ):\n",
    "        output_hidden_states = self.main_model(input_ids=inputs[0], attention_mask=inputs[1], training=training)[-2]\n",
    "        concat_hidden_states = tf.concat(\n",
    "            output_hidden_states[-1:], axis=-1\n",
    "        )  # [B * K, T, F]\n",
    "        concat_hidden_states = self.support_dense(\n",
    "            concat_hidden_states\n",
    "        )  # [B * K, T, 768]\n",
    "        sequence_embeddings = concat_hidden_states[:, 0, :]  # [B * K, 768]\n",
    "        if sequence_labels is not None:\n",
    "            sequence_labels = tf.cast(\n",
    "                sequence_labels, dtype=concat_hidden_states.dtype\n",
    "            )[..., None]\n",
    "            mask_embeddings = self._compute_avg_embeddings(\n",
    "                concat_hidden_states,\n",
    "                tf.where(sequence_labels == -100, 0.0, sequence_labels),\n",
    "                self.K,\n",
    "            )\n",
    "            nomask_embeddings = self._compute_avg_embeddings(\n",
    "                concat_hidden_states,\n",
    "                1.0 - tf.where(sequence_labels == -100, 1.0, sequence_labels),\n",
    "                K=self.K,\n",
    "            )\n",
    "            return sequence_embeddings, mask_embeddings, nomask_embeddings\n",
    "        else:\n",
    "            attention_mask = tf.cast(inputs[1], concat_hidden_states.dtype)[\n",
    "                ..., None\n",
    "            ]  # [B, T, 1]\n",
    "            normed_mask_embeddings = tf.nn.l2_normalize(mask_embeddings, axis=1)[..., None]\n",
    "            normed_nomask_embeddings = tf.nn.l2_normalize(nomask_embeddings, axis=1)[..., None]\n",
    "            normed_hidden_states = tf.nn.l2_normalize(concat_hidden_states, axis=-1)\n",
    "            mask_cosine_similarity = tf.matmul(\n",
    "                normed_hidden_states, normed_mask_embeddings\n",
    "            )  # [B, T, 1]\n",
    "            nomask_cosine_similarity = tf.matmul(\n",
    "                normed_hidden_states, normed_nomask_embeddings\n",
    "            )  # [B, T, 1]\n",
    "            mask_attentions = tf.nn.sigmoid(10.0 * mask_cosine_similarity)  # [B, T, 1]\n",
    "            nomask_attentions = tf.nn.sigmoid(10.0 * nomask_cosine_similarity)  # [B, T, 1]\n",
    "\n",
    "            # average attention\n",
    "            if use_only_mask:\n",
    "                attentions = mask_attentions\n",
    "            else:\n",
    "                attentions = 0.5 * (mask_attentions + (1.0 - nomask_attentions))\n",
    "\n",
    "            attentions *= attention_mask\n",
    "\n",
    "            # compute mask and nomask embeddings\n",
    "            mask_embeddings = self._compute_avg_embeddings(\n",
    "                concat_hidden_states,\n",
    "                tf.where(attention_mask == 0, 0.0, attentions),\n",
    "                K=1,\n",
    "            )\n",
    "            nomask_embeddings = self._compute_avg_embeddings(\n",
    "                concat_hidden_states,\n",
    "                1.0 - tf.where(attention_mask == 0, 1.0, attentions),\n",
    "                K=1,\n",
    "            )\n",
    "            return sequence_embeddings, mask_embeddings, nomask_embeddings, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-washington",
   "metadata": {
    "papermill": {
     "duration": 0.034187,
     "end_time": "2021-06-24T12:41:28.670494",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.636307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amino-composer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.746148Z",
     "iopub.status.busy": "2021-06-24T12:41:28.745373Z",
     "iopub.status.idle": "2021-06-24T12:41:28.748072Z",
     "shell.execute_reply": "2021-06-24T12:41:28.747622Z",
     "shell.execute_reply.started": "2021-06-24T12:36:56.033598Z"
    },
    "papermill": {
     "duration": 0.043285,
     "end_time": "2021-06-24T12:41:28.748182",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.704897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_all_start_end(attention_values):\n",
    "    start_offset = {}\n",
    "    current_idx = 0\n",
    "    is_start = False\n",
    "    start_end = []\n",
    "    while current_idx < len(attention_values):\n",
    "        if attention_values[current_idx] == 1 and is_start is False:\n",
    "            start_offset[current_idx] = 0\n",
    "            is_start = True\n",
    "            start_idx = current_idx\n",
    "        elif attention_values[current_idx] == 1 and is_start is True:\n",
    "            start_offset[start_idx] += 1\n",
    "        elif attention_values[current_idx] == 0 and is_start is True:\n",
    "            is_start = False\n",
    "        current_idx += 1\n",
    "    for k, v in start_offset.items():\n",
    "        start_end.append([k, k + v + 1])\n",
    "    return start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flexible-canberra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.822029Z",
     "iopub.status.busy": "2021-06-24T12:41:28.821415Z",
     "iopub.status.idle": "2021-06-24T12:41:28.824290Z",
     "shell.execute_reply": "2021-06-24T12:41:28.823897Z",
     "shell.execute_reply.started": "2021-06-24T12:36:56.174747Z"
    },
    "papermill": {
     "duration": 0.041856,
     "end_time": "2021-06-24T12:41:28.824393",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.782537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(x1, x2):\n",
    "    x1_norm = tf.nn.l2_normalize(x1, axis=1)\n",
    "    x2_norm = tf.nn.l2_normalize(x2, axis=1)\n",
    "    cosine_similarity = tf.matmul(x1_norm, x2_norm, transpose_b=True)  # [B1, B2]\n",
    "    return tf.clip_by_value(cosine_similarity, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "interim-massage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.906121Z",
     "iopub.status.busy": "2021-06-24T12:41:28.905474Z",
     "iopub.status.idle": "2021-06-24T12:41:28.908274Z",
     "shell.execute_reply": "2021-06-24T12:41:28.907896Z",
     "shell.execute_reply.started": "2021-06-24T12:36:56.349402Z"
    },
    "papermill": {
     "duration": 0.049862,
     "end_time": "2021-06-24T12:41:28.908383",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.858521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(test_dataloader, \n",
    "                  model, all_support_embeddings, \n",
    "                  all_support_mask_embeddings, \n",
    "                  all_support_nomask_embeddings, ner_threshold=[0.5, 0.7]):\n",
    "    preds = []\n",
    "    preds_low_confidence = []\n",
    "    cosines = []\n",
    "    ids = []\n",
    "    text_ids = []\n",
    "    inputs = []\n",
    "    N_TTA = 100\n",
    "    \n",
    "    tokenizer = test_dataloader.tokenizer\n",
    "\n",
    "    for query_batch in tqdm(test_dataloader):\n",
    "        all_cosines = []\n",
    "        support_embeddings = all_support_embeddings[\n",
    "            np.random.choice(range(all_support_embeddings.shape[0]), \n",
    "                             size=query_batch[\"input_ids\"].shape[0] * N_TTA)\n",
    "        ]\n",
    "        support_mask_embeddings = all_support_mask_embeddings[\n",
    "            np.random.choice(range(all_support_mask_embeddings.shape[0]), \n",
    "                             size=query_batch[\"input_ids\"].shape[0] * N_TTA)\n",
    "        ]\n",
    "        support_nomask_embeddings = all_support_nomask_embeddings[\n",
    "            np.random.choice(range(all_support_nomask_embeddings.shape[0]), \n",
    "                             size=query_batch[\"input_ids\"].shape[0] * N_TTA)\n",
    "        ]\n",
    "        support_mask_embeddings = np.mean(np.reshape(support_mask_embeddings, (-1, N_TTA, 768)), axis=1)\n",
    "        support_nomask_embeddings = np.mean(np.reshape(support_nomask_embeddings, (-1, N_TTA, 768)), axis=1)\n",
    "        query_embeddings, query_mask_embeddings, query_nomask_embeddings, attention_values = model(\n",
    "            [\n",
    "                query_batch[\"input_ids\"],\n",
    "                query_batch[\"attention_mask\"],\n",
    "            ],\n",
    "            training=False,\n",
    "            sequence_labels=None,\n",
    "            mask_embeddings=support_mask_embeddings,\n",
    "            nomask_embeddings=support_nomask_embeddings,\n",
    "        )  # [B, F]\n",
    "        cosine = compute_cosine_similarity(query_embeddings, support_embeddings).numpy()\n",
    "        cosine = np.mean(cosine, axis=1)\n",
    "        all_cosines.extend(cosine)\n",
    "        ids.extend(query_batch[\"ids\"])\n",
    "        for k in range(len(all_cosines)):\n",
    "            for TH in ner_threshold:\n",
    "                binary_pred_at_th = attention_values.numpy()[k, :, 0] >= TH\n",
    "                if np.sum(binary_pred_at_th) > 0:\n",
    "                    binary_pred_at_th = binary_pred_at_th.astype(np.int32)\n",
    "                    start_end = find_all_start_end(binary_pred_at_th)\n",
    "                    pred_candidates = []\n",
    "                    for s_e in start_end:\n",
    "                        if (s_e[1] - s_e[0]) >= 4:\n",
    "                            pred_tokens = list(range(s_e[0], s_e[1]))\n",
    "                            pred = tokenizer.decode(query_batch[\"input_ids\"][k, ...][pred_tokens])\n",
    "                            pred_candidates.append(pred)\n",
    "                    pred = \"|\".join(pred_candidates)\n",
    "                else:\n",
    "                    pred = \"\"\n",
    "                if TH == 0.7:\n",
    "                    preds.append(pred)\n",
    "                else:\n",
    "                    preds_low_confidence.append(pred)\n",
    "            cosines.append(all_cosines[k])\n",
    "    return ids, text_ids, inputs, cosines, preds, preds_low_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dynamic-group",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:28.989072Z",
     "iopub.status.busy": "2021-06-24T12:41:28.988397Z",
     "iopub.status.idle": "2021-06-24T12:41:28.991251Z",
     "shell.execute_reply": "2021-06-24T12:41:28.990864Z",
     "shell.execute_reply.started": "2021-06-24T12:36:56.502396Z"
    },
    "papermill": {
     "duration": 0.048236,
     "end_time": "2021-06-24T12:41:28.991352",
     "exception": false,
     "start_time": "2021-06-24T12:41:28.943116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def end2end(pretrained_path, checkpoint_path, test_df, ner_threshold=[0.5, 0.7]):\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        f\"/kaggle/input/{pretrained_path}/\")\n",
    "    config.output_attentions = True\n",
    "    config.output_hidden_states = True\n",
    "\n",
    "    main_model = TFAutoModel.from_config(config=config)\n",
    "    model = MetricLearningModel(config=config, name=\"metric_learning_model\")\n",
    "    model.main_model = main_model\n",
    "    model.K = 3\n",
    "    \n",
    "    # load pre-extract embedding\n",
    "    checkpoint_path = f\"/kaggle/input/{checkpoint_path}\"\n",
    "    all_support_embeddings = np.load(os.path.join(checkpoint_path, \"support_embeddings.npy\"))\n",
    "    all_support_mask_embeddings = np.load(os.path.join(checkpoint_path, \"support_mask_embeddings.npy\"))\n",
    "    all_support_nomask_embeddings = np.load(os.path.join(checkpoint_path, \"support_nomask_embeddings.npy\"))\n",
    "    \n",
    "    \n",
    "    # create tokenizer and dataloader\n",
    "    if \"distil\" in pretrained_path:\n",
    "        tokenizer = DistilBertTokenizerFast.from_pretrained(f\"/kaggle/input/{pretrained_path}/\")\n",
    "    elif \"roberta\" in pretrained_path:\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained(f\"/kaggle/input/{pretrained_path}/\")\n",
    "    elif \"scibert\" in pretrained_path:\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(f\"/kaggle/input/{pretrained_path}/\", do_lower_case=False)\n",
    "\n",
    "    query_dataloader = QueryDataLoader(test_df, batch_size=128)\n",
    "    test_dataloader = SupportQueryDataLoader(\n",
    "        test_df,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=128,\n",
    "        is_train=False,\n",
    "        training_steps=len(query_dataloader),\n",
    "        query_dataloader=query_dataloader,\n",
    "        return_query_ids=True,\n",
    "    )\n",
    "    \n",
    "    # build model with real input and load_weights\n",
    "    query_batch = test_dataloader.__getitem__(0)\n",
    "    (\n",
    "        query_embeddings,\n",
    "        query_mask_embeddings,\n",
    "        query_nomask_embeddings,\n",
    "        attention_values,\n",
    "    ) = model(\n",
    "        [\n",
    "            query_batch[\"input_ids\"][:1, ...],\n",
    "            query_batch[\"attention_mask\"][:1, ...],\n",
    "        ],\n",
    "        training=True,\n",
    "        sequence_labels=None,\n",
    "        mask_embeddings=all_support_mask_embeddings[:1, ...],\n",
    "        nomask_embeddings=all_support_nomask_embeddings[:1, ...],\n",
    "    )  # [B, F]\n",
    "    model.summary()\n",
    "    weights_path = glob.glob(os.path.join(checkpoint_path, \"*.h5\"))[0]\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    \n",
    "    # apply tf.function\n",
    "    model = tf.function(model, experimental_relax_shapes=True)\n",
    "    \n",
    "    # run inference\n",
    "    ids, text_ids, inputs, cosines, preds, preds_low_confidence = run_inference(\n",
    "        test_dataloader, \n",
    "        model, \n",
    "        all_support_embeddings, \n",
    "        all_support_mask_embeddings, \n",
    "        all_support_nomask_embeddings,\n",
    "        ner_threshold=ner_threshold\n",
    "    )\n",
    "    \n",
    "    # release model\n",
    "    del_everything(model)\n",
    "    \n",
    "    return ids, text_ids, inputs, cosines, preds, preds_low_confidence, test_dataloader.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "plastic-costume",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.065404Z",
     "iopub.status.busy": "2021-06-24T12:41:29.064904Z",
     "iopub.status.idle": "2021-06-24T12:41:29.569336Z",
     "shell.execute_reply": "2021-06-24T12:41:29.567837Z",
     "shell.execute_reply.started": "2021-06-24T12:36:56.622088Z"
    },
    "papermill": {
     "duration": 0.543438,
     "end_time": "2021-06-24T12:41:29.569473",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.026035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_stopwords(string):\n",
    "    word_tokens = word_tokenize(string) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return \" \".join(filtered_sentence).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indirect-princess",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.645289Z",
     "iopub.status.busy": "2021-06-24T12:41:29.644047Z",
     "iopub.status.idle": "2021-06-24T12:41:29.646532Z",
     "shell.execute_reply": "2021-06-24T12:41:29.646915Z",
     "shell.execute_reply.started": "2021-06-24T12:36:57.122962Z"
    },
    "papermill": {
     "duration": 0.042492,
     "end_time": "2021-06-24T12:41:29.647049",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.604557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_special_token(string, tokenizer):\n",
    "    pad_token = tokenizer.pad_token\n",
    "    sep_token = tokenizer.sep_token\n",
    "    cls_token = tokenizer.cls_token\n",
    "    \n",
    "    if (pad_token not in string) and (sep_token not in string) and (cls_token not in string):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alternative-spyware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.720344Z",
     "iopub.status.busy": "2021-06-24T12:41:29.719731Z",
     "iopub.status.idle": "2021-06-24T12:41:29.722719Z",
     "shell.execute_reply": "2021-06-24T12:41:29.722304Z",
     "shell.execute_reply.started": "2021-06-24T12:36:57.132560Z"
    },
    "papermill": {
     "duration": 0.041165,
     "end_time": "2021-06-24T12:41:29.722837",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.681672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(txt, lower=True):\n",
    "    if lower:\n",
    "        return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "    else:\n",
    "        return re.sub('[^A-Za-z0-9]+', ' ', str(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stupid-cycle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.796298Z",
     "iopub.status.busy": "2021-06-24T12:41:29.795547Z",
     "iopub.status.idle": "2021-06-24T12:41:29.797850Z",
     "shell.execute_reply": "2021-06-24T12:41:29.798323Z",
     "shell.execute_reply.started": "2021-06-24T12:36:57.140487Z"
    },
    "papermill": {
     "duration": 0.041154,
     "end_time": "2021-06-24T12:41:29.798436",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.757282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(str1, str2): \n",
    "    a = set(str1.lower().split(\" \"))\n",
    "    b = set(str2.lower().split(\" \"))\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sunset-plenty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.882072Z",
     "iopub.status.busy": "2021-06-24T12:41:29.881301Z",
     "iopub.status.idle": "2021-06-24T12:41:29.884222Z",
     "shell.execute_reply": "2021-06-24T12:41:29.883830Z",
     "shell.execute_reply.started": "2021-06-24T12:36:57.699109Z"
    },
    "papermill": {
     "duration": 0.051512,
     "end_time": "2021-06-24T12:41:29.884329",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.832817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_cased_pred(lower_start_idx, lower_end_idx, lower_string, cased_string, lower_pred):\n",
    "    len_lower_string = len(lower_string)\n",
    "    len_cased_string = len(cased_string)\n",
    "    if (len_lower_string - len_cased_string) == 0:\n",
    "        return cased_string[lower_start_idx: lower_end_idx]\n",
    "    else:\n",
    "        diff_len = abs(len_lower_string - lower_end_idx)\n",
    "        for shift_idx in range(-diff_len - 1, diff_len + 1):\n",
    "            cased_pred_candidate = cased_string[lower_start_idx + shift_idx : lower_start_idx + shift_idx + len(lower_pred)]\n",
    "            if cased_pred_candidate.lower() == lower_pred:\n",
    "                return cased_pred_candidate\n",
    "    return lower_pred.upper()\n",
    "\n",
    "\n",
    "def calculate_iou(se_0, se_1):\n",
    "    s_0, e_0 = se_0\n",
    "    s_1, e_1 = se_1    \n",
    "    max_s = max(s_0, s_1)\n",
    "    min_e = min(e_0, e_1)\n",
    "    intersection = (min_e - max_s)\n",
    "    return  intersection / ((e_0 - s_0) + (e_1 - s_1) - intersection)\n",
    "\n",
    "\n",
    "def find_all_pred_in_text(normed_text_cased, all_unique_preds):\n",
    "    normed_text_cased = clean_text(normed_text_cased, False)\n",
    "    normed_text = normed_text_cased.lower()\n",
    "    preds = []\n",
    "    preds_indexs = []\n",
    "    for pred in all_unique_preds:\n",
    "        if (\" \" + pred + \" \" in normed_text) or (\" \" + pred + \",\" in normed_text) or (\" \" + pred + \".\" in normed_text):\n",
    "            preds.append(pred)\n",
    "    unique_preds = [] # unique in terms of index. \n",
    "    preds = list(sorted(preds, key=len))\n",
    "    for pred in preds:\n",
    "        matchs = re.finditer(pred, normed_text)\n",
    "        for match in matchs:\n",
    "            start_index = match.start()\n",
    "            end_index = match.end()\n",
    "            pred_cased = find_cased_pred(start_index, end_index, normed_text, normed_text_cased, pred)\n",
    "            if pred_cased.islower() is False:\n",
    "                preds_indexs.append([start_index, end_index])\n",
    "                unique_preds.append(pred)\n",
    "    group_idxs = []\n",
    "    for i in range(len(preds_indexs)):\n",
    "        for j in range(len(preds_indexs)):\n",
    "            if i != j:\n",
    "                start_i, end_i = preds_indexs[i]\n",
    "                start_j, end_j = preds_indexs[j]\n",
    "                iou = calculate_iou(preds_indexs[i], preds_indexs[j])\n",
    "                if (start_i <= end_j and end_i <= end_j and start_i >= start_j) or iou >= 0.1:\n",
    "                    group_idxs.append([i, j])\n",
    "    unique_preds = np.array(unique_preds)\n",
    "    for group_idx in group_idxs:\n",
    "        unique_preds[group_idx[0]] = unique_preds[group_idx[1]]\n",
    "    return np.unique(unique_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unavailable-marble",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:29.960821Z",
     "iopub.status.busy": "2021-06-24T12:41:29.960056Z",
     "iopub.status.idle": "2021-06-24T12:41:29.962722Z",
     "shell.execute_reply": "2021-06-24T12:41:29.962324Z",
     "shell.execute_reply.started": "2021-06-24T12:36:57.873806Z"
    },
    "papermill": {
     "duration": 0.044014,
     "end_time": "2021-06-24T12:41:29.962842",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.918828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove acronym from prediction\n",
    "def remove_acronym(preds):\n",
    "    for i in range(len(preds)):\n",
    "        pred_i = preds[i]\n",
    "        pred_i = pred_i.replace(\"( \", \"(\")\n",
    "        pred_i = pred_i.replace(\" )\", \")\")\n",
    "        pred_i = pred_i.replace(\"[ \", \"[\")\n",
    "        pred_i = pred_i.replace(\" ]\", \"]\")\n",
    "        try:\n",
    "            new_pred_i = []\n",
    "            for pi in pred_i.split(\"|\"):\n",
    "                if pi != \"\":\n",
    "                    words = pi.split()\n",
    "                    if \"(\" in words[-1] or \"[\" in words[-1]:\n",
    "                        new_pred_i.append(\" \".join(words[:-1]))\n",
    "                    else:\n",
    "                        new_pred_i.append(pi)\n",
    "            new_pred_i = \"|\".join(new_pred_i)\n",
    "            preds[i] = new_pred_i\n",
    "        except:\n",
    "            pass\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "engaging-travel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:30.038301Z",
     "iopub.status.busy": "2021-06-24T12:41:30.037573Z",
     "iopub.status.idle": "2021-06-24T12:41:30.040501Z",
     "shell.execute_reply": "2021-06-24T12:41:30.040106Z",
     "shell.execute_reply.started": "2021-06-24T12:36:58.868595Z"
    },
    "papermill": {
     "duration": 0.042973,
     "end_time": "2021-06-24T12:41:30.040606",
     "exception": false,
     "start_time": "2021-06-24T12:41:29.997633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_overlap(preds, preds_low_confidence):\n",
    "    for i in range(len(preds_low_confidence)):\n",
    "        if preds[i] == \"\" or preds_low_confidence[i] == \"\":\n",
    "            continue\n",
    "        pred_i = preds[i].split(\"|\")\n",
    "        pred_low_conf_i = preds_low_confidence[i].split(\"|\")\n",
    "        new_p_low = []\n",
    "        for p_low in pred_low_conf_i:\n",
    "            overlap = False\n",
    "            for p in pred_i:\n",
    "                if p in p_low:\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if overlap is False:\n",
    "                new_p_low.append(p_low)\n",
    "        if len(new_p_low) == 0:\n",
    "            preds_low_confidence[i] = \"\"\n",
    "        else:\n",
    "            preds_low_confidence[i] = \"|\".join(new_p_low)\n",
    "    return preds_low_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "controlled-elite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:30.116744Z",
     "iopub.status.busy": "2021-06-24T12:41:30.116101Z",
     "iopub.status.idle": "2021-06-24T12:41:30.118944Z",
     "shell.execute_reply": "2021-06-24T12:41:30.118541Z",
     "shell.execute_reply.started": "2021-06-24T12:36:59.014395Z"
    },
    "papermill": {
     "duration": 0.043714,
     "end_time": "2021-06-24T12:41:30.119048",
     "exception": false,
     "start_time": "2021-06-24T12:41:30.075334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_valid_low_confidence_pred(pred):\n",
    "    clean_pred = clean_text(pred, True)\n",
    "    keywords = [\"study\", \"survey\", \"studies\", \"database\", \"dataset\", \"data system\", \"system data\", \"data set\", \"data base\", \"program\"]\n",
    "    if pred != \"\":\n",
    "        words = pred.strip().split()\n",
    "        clean_words = clean_pred.strip().split()\n",
    "        string_check= re.compile('[\\(\\)\\[\\]]')\n",
    "        if clean_words[0] in [\"a\", \"an\", \"the\"]:\n",
    "            return False\n",
    "        if clean_words[-1] in [\"a\", \"an\", \"the\", \"in\", \"on\", \"of\", \"for\", \"and\", \"or\"]:\n",
    "            return False\n",
    "        if words[0][0].isalpha() and words[0][0].isupper() and string_check.search(words[0]) is None:\n",
    "            for kw in keywords:\n",
    "                if kw in clean_pred:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dense-tamil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:30.193314Z",
     "iopub.status.busy": "2021-06-24T12:41:30.192560Z",
     "iopub.status.idle": "2021-06-24T12:41:30.225604Z",
     "shell.execute_reply": "2021-06-24T12:41:30.226293Z",
     "shell.execute_reply.started": "2021-06-24T12:40:20.701509Z"
    },
    "papermill": {
     "duration": 0.072912,
     "end_time": "2021-06-24T12:41:30.226452",
     "exception": false,
     "start_time": "2021-06-24T12:41:30.153540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create raw text per id: 100%|██████████| 4/4 [00:00<00:00, 145.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# create text per id\n",
    "raw_text_per_id = {}\n",
    "clean_text_per_id = {}\n",
    "all_unique_ids = unique_ids\n",
    "\n",
    "for i in tqdm(range(len(all_unique_ids)), desc=\"Create raw text per id\"):\n",
    "    full_text = full_texts[i]\n",
    "    if id not in raw_text_per_id:\n",
    "        raw_text_per_id[all_unique_ids[i]] = full_text\n",
    "        clean_text_per_id[all_unique_ids[i]] = clean_text(full_text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "induced-store",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:30.309002Z",
     "iopub.status.busy": "2021-06-24T12:41:30.308331Z",
     "iopub.status.idle": "2021-06-24T12:41:30.311189Z",
     "shell.execute_reply": "2021-06-24T12:41:30.310679Z",
     "shell.execute_reply.started": "2021-06-24T12:40:22.087977Z"
    },
    "papermill": {
     "duration": 0.049154,
     "end_time": "2021-06-24T12:41:30.311293",
     "exception": false,
     "start_time": "2021-06-24T12:41:30.262139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all accepted preds\n",
    "def get_accepted_preds(preds, preds_low_confidence, cosines, cosine_threshold, tokenizer):\n",
    "    accepted_preds = []\n",
    "    ########################################################\n",
    "    all_accepted_preds = []\n",
    "    for i in range(len(preds)):\n",
    "        if cosines[i] >= cosine_threshold:\n",
    "            a = preds[i].split(\"|\")\n",
    "            unique_v = np.unique(a)\n",
    "            all_accepted_preds.extend(unique_v)\n",
    "        else:\n",
    "            preds_low_confidence_i = preds_low_confidence[i].split(\"|\")\n",
    "            preds_low_confidence_i.extend(preds[i].split(\"|\"))\n",
    "            preds_low_confidence[i] = \"|\".join(preds_low_confidence_i)\n",
    "            \n",
    "            \n",
    "    counter_all_accepted_preds = Counter(all_accepted_preds)\n",
    "    for k, v in counter_all_accepted_preds.items():\n",
    "        k = k.strip()\n",
    "        if (\"#\" not in k) and len(clean_text(k).strip().split(\" \")) >= 3 and len(k.split(\" \")) >= 3 and len(remove_stopwords(k).split(\" \")) >= 3 and len(k) >= 10 and check_special_token(k, tokenizer):\n",
    "            if v >= 4:\n",
    "                accepted_preds.append(clean_text(k).strip())\n",
    "            else:\n",
    "                if check_valid_low_confidence_pred(k):\n",
    "                    accepted_preds.append(clean_text(k).strip())\n",
    "\n",
    "    ########################################################\n",
    "    all_accepted_preds = []\n",
    "    for i in range(len(preds_low_confidence)):\n",
    "        if cosines[i] >= -1.0:\n",
    "            a = preds_low_confidence[i].split(\"|\")\n",
    "            unique_v = np.unique(a)\n",
    "            all_accepted_preds.extend(unique_v)\n",
    "    counter_all_accepted_preds = Counter(all_accepted_preds)\n",
    "    for k, v in counter_all_accepted_preds.items():\n",
    "        k = k.strip()\n",
    "        if (\"#\" not in k) and len(clean_text(k).strip().split(\" \")) >= 3 and len(k.split(\" \")) >= 3 and len(remove_stopwords(k).split(\" \")) >= 3 and len(k) >= 10 and check_special_token(k, tokenizer):\n",
    "            if check_valid_low_confidence_pred(k):\n",
    "                accepted_preds.append(clean_text(k).strip())\n",
    "\n",
    "    accepted_preds = list(set(accepted_preds))\n",
    "    return accepted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "limited-stewart",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:41:30.387520Z",
     "iopub.status.busy": "2021-06-24T12:41:30.387031Z",
     "iopub.status.idle": "2021-06-24T12:42:27.888514Z",
     "shell.execute_reply": "2021-06-24T12:42:27.888047Z",
     "shell.execute_reply.started": "2021-06-24T12:40:22.227917Z"
    },
    "papermill": {
     "duration": 57.541878,
     "end_time": "2021-06-24T12:42:27.888642",
     "exception": false,
     "start_time": "2021-06-24T12:41:30.346764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"metric_learning_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  590592    \n",
      "_________________________________________________________________\n",
      "tf_roberta_model (TFRobertaM multiple                  124645632 \n",
      "=================================================================\n",
      "Total params: 125,236,224\n",
      "Trainable params: 125,236,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:16<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"metric_learning_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  590592    \n",
      "_________________________________________________________________\n",
      "tf_bert_model (TFBertModel)  multiple                  109938432 \n",
      "=================================================================\n",
      "Total params: 110,529,024\n",
      "Trainable params: 110,529,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "accepted_preds = []\n",
    "\n",
    "\n",
    "PARAMS = [\n",
    "    (\"pretrainedbiomedrobertabase\", \"coleridgeinitiativebiomedrobertabasev2\", [0.5, 0.7], -0.1),\n",
    "    (\"scibertbasecased\", \"coleridgeinitiativescibertbasecasedv10\", [0.5, 0.7], -0.7),\n",
    "]\n",
    "\n",
    "for i, param in enumerate(PARAMS):\n",
    "    ids, text_ids, inputs, cosines, preds, preds_low_confidence, tokenizer = end2end(\n",
    "        param[0], \n",
    "        param[1], \n",
    "        test_df,\n",
    "        ner_threshold=param[2])\n",
    "\n",
    "    preds = remove_acronym(preds)\n",
    "    preds_low_confidence = remove_acronym(preds_low_confidence)\n",
    "    preds_low_confidence = remove_overlap(preds, preds_low_confidence)\n",
    "    accepted_preds.extend(get_accepted_preds(preds, preds_low_confidence, cosines, param[3], tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "recent-monroe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:27.972421Z",
     "iopub.status.busy": "2021-06-24T12:42:27.971141Z",
     "iopub.status.idle": "2021-06-24T12:42:27.973878Z",
     "shell.execute_reply": "2021-06-24T12:42:27.973469Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.286986Z"
    },
    "papermill": {
     "duration": 0.046141,
     "end_time": "2021-06-24T12:42:27.973987",
     "exception": false,
     "start_time": "2021-06-24T12:42:27.927846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accepted_preds = list(set(accepted_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-arbitration",
   "metadata": {
    "papermill": {
     "duration": 0.038223,
     "end_time": "2021-06-24T12:42:28.050673",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.012450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Make Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "industrial-honor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.132081Z",
     "iopub.status.busy": "2021-06-24T12:42:28.131544Z",
     "iopub.status.idle": "2021-06-24T12:42:28.136287Z",
     "shell.execute_reply": "2021-06-24T12:42:28.136662Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.293012Z"
    },
    "papermill": {
     "duration": 0.047287,
     "end_time": "2021-06-24T12:42:28.136805",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.089518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nc coastal erosion study',\n",
       " 'trends in international mathematics and science study',\n",
       " 'consumer expenditure survey',\n",
       " 'progress in international reading literacy study',\n",
       " 'sea level rise risk management study',\n",
       " 'coastal erosion study',\n",
       " 'international mathematics and science study',\n",
       " 'national health and nutrition examination survey national food']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "possible-effects",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.220167Z",
     "iopub.status.busy": "2021-06-24T12:42:28.219351Z",
     "iopub.status.idle": "2021-06-24T12:42:28.255806Z",
     "shell.execute_reply": "2021-06-24T12:42:28.256370Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.305354Z"
    },
    "papermill": {
     "duration": 0.080857,
     "end_time": "2021-06-24T12:42:28.256537",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.175680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 125.91it/s]\n"
     ]
    }
   ],
   "source": [
    "group_label_per_id = {}\n",
    "\n",
    "for i in tqdm(range(len(all_unique_ids))):\n",
    "    full_text = raw_text_per_id[all_unique_ids[i]]\n",
    "    merged_pred_labels = find_all_pred_in_text(full_text, np.unique(accepted_preds))\n",
    "    group_label_per_id[all_unique_ids[i]] = []\n",
    "    group_label_per_id[all_unique_ids[i]].extend(merged_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "mathematical-agent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.347058Z",
     "iopub.status.busy": "2021-06-24T12:42:28.346210Z",
     "iopub.status.idle": "2021-06-24T12:42:28.348455Z",
     "shell.execute_reply": "2021-06-24T12:42:28.348873Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.350243Z"
    },
    "papermill": {
     "duration": 0.051753,
     "end_time": "2021-06-24T12:42:28.349008",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.297255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_valid_ac(long_form, short_form):\n",
    "    long_form = \"\".join([w[0] for w in long_form.split()])\n",
    "    short_form_candidate1 = \"\".join(\n",
    "        [w if i == 0 else w[0] for i, w in enumerate(short_form.split())]\n",
    "    )\n",
    "    short_form_candidate2 = short_form.split()[0]\n",
    "    short_form_accepted = None\n",
    "    original_long_index = len(long_form) - 1\n",
    "    for i, short_form_candidate in enumerate([short_form_candidate1, short_form_candidate2]):\n",
    "        long_index = len(long_form) - 1\n",
    "        short_index = len(short_form_candidate) - 1\n",
    "\n",
    "        while short_index >= 0:\n",
    "            current_charactor = short_form_candidate[short_index]\n",
    "            if not current_charactor.isalpha():\n",
    "                short_index -= 1\n",
    "                continue\n",
    "\n",
    "            while long_form[long_index] != current_charactor:\n",
    "                long_index -= 1\n",
    "                if long_index < 0:\n",
    "                    break\n",
    "\n",
    "            short_index -= 1\n",
    "            if long_index < 0:\n",
    "                break\n",
    "                \n",
    "        if long_index >= 0 and (not short_form.isdigit()) and long_index < original_long_index:\n",
    "            if i == 0:\n",
    "                short_form_accepted = short_form\n",
    "            else:\n",
    "                short_form_accepted = short_form.split()[0]\n",
    "                \n",
    "            if not (short_form_accepted[-1].isalpha() or short_form_accepted[-1].isdigit()):\n",
    "                short_form_accepted = short_form_accepted[:-1]\n",
    "            return short_form_accepted\n",
    "\n",
    "    return short_form_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "latter-anime",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.433504Z",
     "iopub.status.busy": "2021-06-24T12:42:28.432844Z",
     "iopub.status.idle": "2021-06-24T12:42:28.435888Z",
     "shell.execute_reply": "2021-06-24T12:42:28.435441Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.362253Z"
    },
    "papermill": {
     "duration": 0.046554,
     "end_time": "2021-06-24T12:42:28.435997",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.389443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text_v2(txt):\n",
    "    return re.sub('[^A-Za-z0-9\\(\\)\\[\\]]+', ' ', str(txt).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-council",
   "metadata": {
    "papermill": {
     "duration": 0.039723,
     "end_time": "2021-06-24T12:42:28.515971",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.476248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "arctic-retrieval",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.601914Z",
     "iopub.status.busy": "2021-06-24T12:42:28.601272Z",
     "iopub.status.idle": "2021-06-24T12:42:28.604154Z",
     "shell.execute_reply": "2021-06-24T12:42:28.603749Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.376059Z"
    },
    "papermill": {
     "duration": 0.048604,
     "end_time": "2021-06-24T12:42:28.604257",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.555653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_all_acronyms_candidates(group_label_per_id):\n",
    "    for k in group_label_per_id.keys():\n",
    "        string = clean_text_v2(raw_text_per_id[k])\n",
    "        all_labels = group_label_per_id[k].split(\"|\")\n",
    "        for label in all_labels:\n",
    "            if label != \"\":\n",
    "                acronyms_candidates = re.findall(f\"{label} \\((.*?)\\)\", string)\n",
    "                acronyms_candidates.extend(re.findall(f\"{label} \\[(.*?)\\]\", string))\n",
    "                acronyms_candidates = np.unique([ac for ac in acronyms_candidates if len(ac.split()) >= 1])\n",
    "                if len(acronyms_candidates) > 0:\n",
    "                    for ac in acronyms_candidates:\n",
    "                        ac = find_valid_ac(label, ac)\n",
    "                        if ac is not None:\n",
    "                            if len(ac.split(\" \")) <= 2:\n",
    "                                group_label_per_id[k] += f\"|{ac}\"\n",
    "    return group_label_per_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "independent-status",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.690648Z",
     "iopub.status.busy": "2021-06-24T12:42:28.689014Z",
     "iopub.status.idle": "2021-06-24T12:42:28.691240Z",
     "shell.execute_reply": "2021-06-24T12:42:28.691624Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.386819Z"
    },
    "papermill": {
     "duration": 0.047885,
     "end_time": "2021-06-24T12:42:28.691742",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.643857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, v in group_label_per_id.items():\n",
    "    unique_v = list(np.unique(v))\n",
    "    if len(unique_v) >= 2:\n",
    "        group_label_per_id[k] = \"|\".join([v for v in unique_v if v != ''])\n",
    "    elif len(unique_v) == 1 and unique_v[0] == '':\n",
    "        group_label_per_id[k] = ''\n",
    "    elif len(unique_v) == 1 and unique_v[0] != '':\n",
    "        group_label_per_id[k] = f'{unique_v[0]}'\n",
    "    else:\n",
    "        group_label_per_id[k] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ordered-trinity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.805019Z",
     "iopub.status.busy": "2021-06-24T12:42:28.804079Z",
     "iopub.status.idle": "2021-06-24T12:42:28.849830Z",
     "shell.execute_reply": "2021-06-24T12:42:28.850543Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.398289Z"
    },
    "papermill": {
     "duration": 0.118942,
     "end_time": "2021-06-24T12:42:28.850761",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.731819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_label_per_id = find_all_acronyms_candidates(group_label_per_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unique-allen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:28.992874Z",
     "iopub.status.busy": "2021-06-24T12:42:28.992093Z",
     "iopub.status.idle": "2021-06-24T12:42:28.996670Z",
     "shell.execute_reply": "2021-06-24T12:42:28.997378Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.434668Z"
    },
    "papermill": {
     "duration": 0.077671,
     "end_time": "2021-06-24T12:42:28.997568",
     "exception": false,
     "start_time": "2021-06-24T12:42:28.919897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_ids = []\n",
    "for k in list(group_label_per_id.keys()):\n",
    "    pred = []\n",
    "    pred.extend(group_label_per_id[k].split(\"|\"))\n",
    "    pred = np.unique(pred)\n",
    "    accepted_pred = []\n",
    "    for i in range(len(pred)):\n",
    "        clean_pred = clean_text(pred[i])\n",
    "        pred[i] = clean_pred.strip()\n",
    "        accepted_pred.append(pred[i])\n",
    "    y_pred.append(list(pred))\n",
    "    y_ids.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "federal-scanning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:29.153308Z",
     "iopub.status.busy": "2021-06-24T12:42:29.152293Z",
     "iopub.status.idle": "2021-06-24T12:42:29.154667Z",
     "shell.execute_reply": "2021-06-24T12:42:29.154032Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.444603Z"
    },
    "papermill": {
     "duration": 0.081344,
     "end_time": "2021-06-24T12:42:29.154906",
     "exception": false,
     "start_time": "2021-06-24T12:42:29.073562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_merged = []\n",
    "for pred in y_pred:\n",
    "    pred = \"|\".join(pred).strip()\n",
    "    y_pred_merged.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "quarterly-narrow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:29.302542Z",
     "iopub.status.busy": "2021-06-24T12:42:29.301832Z",
     "iopub.status.idle": "2021-06-24T12:42:29.409209Z",
     "shell.execute_reply": "2021-06-24T12:42:29.408712Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.453149Z"
    },
    "papermill": {
     "duration": 0.184449,
     "end_time": "2021-06-24T12:42:29.409335",
     "exception": false,
     "start_time": "2021-06-24T12:42:29.224886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = y_ids\n",
    "submission['PredictionString'] = y_pred_merged\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "protected-professional",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T12:42:29.498986Z",
     "iopub.status.busy": "2021-06-24T12:42:29.498314Z",
     "iopub.status.idle": "2021-06-24T12:42:30.188752Z",
     "shell.execute_reply": "2021-06-24T12:42:30.188182Z",
     "shell.execute_reply.started": "2021-06-24T12:40:54.464663Z"
    },
    "papermill": {
     "duration": 0.736345,
     "end_time": "2021-06-24T12:42:30.188920",
     "exception": false,
     "start_time": "2021-06-24T12:42:29.452575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,PredictionString\r\n",
      "8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60,ces|consumer expenditure survey|national health and nutrition examination survey national food\r\n",
      "2100032a-7c33-4bff-97ef-690822c43466,\r\n",
      "2f392438-e215-4169-bebf-21ac4ff253e1,pirls|pirls 2006|progress in international reading literacy study|timss|timss 2007|trends in international mathematics and science study\r\n",
      "3f316b38-1a24-45a9-8d8c-4e05a42257c6,coastal erosion study|nc coastal erosion study|sea level rise risk management study|slrrms\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-calibration",
   "metadata": {
    "papermill": {
     "duration": 0.0426,
     "end_time": "2021-06-24T12:42:30.275183",
     "exception": false,
     "start_time": "2021-06-24T12:42:30.232583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-tracy",
   "metadata": {
    "papermill": {
     "duration": 0.041515,
     "end_time": "2021-06-24T12:42:30.359899",
     "exception": false,
     "start_time": "2021-06-24T12:42:30.318384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 78.959742,
   "end_time": "2021-06-24T12:42:32.213913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T12:41:13.254171",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
