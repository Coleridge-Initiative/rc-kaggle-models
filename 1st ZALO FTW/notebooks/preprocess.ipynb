{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Purpose of This NoteBook\n",
    "\n",
    "Please make sure you've already run the **get_candidate_labels** notebook to extract candidate labels using scispacy and our custom algorithm before running this one.\n",
    "\n",
    "This notebook aim for create training/validation data for training model. We devided all content of the paper into multiple chunks with fixed number of words. If one chunk contains any dataset title from the given training set or our extra labels (from **get_candidate_labels** notebook), we consider that chunk as **positive** sample otherwise, it's a **negative** sample.\n",
    "\n",
    "The labels can be divided into three categories (recognized based on the given dataset labels):\n",
    "\n",
    "    1. LONG FORM\n",
    "    2. LONG FORM (SHORT FORM)\n",
    "    3. SHORT FORM\n",
    "    \n",
    "So, in the training set, if we have a dataset label in the form **\"LONG FORM (SHORT FORM)\"**, we should add **\"LONG FORM\"** and **\"SHORT FORM\"** into the training labels also. If the label only matches the form **\"LONG FORM\"**, we try to find its short form and add it into training labels.\n",
    "\n",
    "To improve the preciseness of the finding dataset process, we found a clean version of the given training labels from a clean paper and returned a (start, end) index then got the original dataset label from a raw paper. For example, we can get the label \"National Study-of Youth\" in the raw paper if our training label contains \"national study of youth\". \n",
    "\n",
    "After finding dataset process complete, we will remove a sample in below cases:\n",
    "\n",
    "    1. Its found dataset label is lower\n",
    "    2. Its found dataset label contains the labels that come from both train and valid labels. Note that a single sample can contain multiple dataset labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import *\n",
    "import pickle\n",
    "from pqdm.processes import pqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = json.load(open(\"../settings.json\", \"rb\"))\n",
    "\n",
    "for k, v in settings.items():\n",
    "    settings[k] = \".\" + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{settings['RAW_DATA_DIR']}/train.csv\")\n",
    "df.drop_duplicates(\"Id\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_s_e_window_sliding(sample_len, win_size, step_size):\n",
    "    start = 0\n",
    "    end = win_size\n",
    "    s_e = []\n",
    "    s_e.append([start, end])\n",
    "    while end < sample_len:\n",
    "        start += step_size\n",
    "        end = start + win_size\n",
    "        s_e.append([start, end])\n",
    "\n",
    "    s_e[-1][0] -= s_e[-1][1] - sample_len\n",
    "    s_e[-1][0] = max(s_e[-1][0], 0)\n",
    "    s_e[-1][1] = sample_len\n",
    "    return s_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_clean_text(txt, is_lower=True):\n",
    "    if is_lower:\n",
    "        return re.sub('[^A-Za-z0-9]\\(\\)', ' ', str(txt).lower())\n",
    "    else:\n",
    "        return re.sub('[^A-Za-z0-9]', ' ', str(txt))\n",
    "    \n",
    "\n",
    "def clean_text(txt, is_lower=True):\n",
    "    if is_lower:\n",
    "        return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "    else:\n",
    "        return re.sub('[^A-Za-z0-9]+', ' ', str(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a ACRONYM MAPPING that we built for training dataset.\n",
    "# A acronym (short form) will be use for training progress.\n",
    "\n",
    "ACRONYM_MAPPING = {'adni': \"alzheimer's disease neuroimaging initiative\",\n",
    " 'blsa': 'baltimore longitudinal study of aging',\n",
    " 'cord-19': 'covid-19 open research dataset',\n",
    " 'coa': 'census of agriculture',\n",
    " 'charybdis': 'characterizing health associated risks and your baseline disease in sars cov 2',\n",
    " 'ccd': 'nces common core of data',\n",
    " 'cccsl': 'complexity science hub covid 19 control strategies list',\n",
    " 'c-cap': 'coastal change analysis program',\n",
    " 'nwlon': 'noaa national water level observation network',\n",
    " 'slosh': 'noaa sea lake and overland surges from hurricanes',\n",
    " 'ibtracs': 'international best-track archive for climate stewardship',\n",
    " 'oisst': 'optimum interpolation sea surface temperature',\n",
    " 'ruccs': 'rural-urban continuum codes',\n",
    " 'bbs': 'north american breeding bird survey',\n",
    " 'agid': 'aging integrated database',\n",
    " 'niagads': 'the national institute on aging genetics of alzheimer s disease data storage site',\n",
    " 'arm': 'agricultural resources management survey',\n",
    " 'b&b': 'baccalaureate and beyond longitudinal study',\n",
    " 'ecls': 'early childhood longitudinal study',\n",
    " 'ecls-b': 'early childhood longitudinal study-birth',\n",
    " 'peels': 'pre-elementary education longitudinal study',\n",
    " 'nlts': 'national longitudinal transition study',\n",
    " 'nlts2': 'national longitudinal transition study-2',\n",
    " 'nels': 'national education longitudinal studies',\n",
    " 'hsls': 'high school longitudinal study',\n",
    " 'naep': 'national assessment of education progress',\n",
    " 'wod': 'noaa world ocean database',\n",
    " 'sdr': 'survey of doctorate recipients',\n",
    " 'isdr': 'international survey of doctoral recipients',\n",
    " 'sed': 'survey of earned doctorates',\n",
    " 'sird': 'survey of industrial research and development',\n",
    " 'ntps': 'national teacher and principal survey',\n",
    " 'piaac': 'program for the international assessment of adult competencies',\n",
    " 'ricord': 'rsna international covid 19 open radiology database',\n",
    " 'ssocs': 'school survey on crime and safety',\n",
    " 'timss': 'trends in international mathematics and science study',\n",
    " 'cels': 'citizenship education longitudinal study',\n",
    " 'kels': 'korea education longitudinal study',\n",
    " 'gels': 'gerontology education longitudinal study',\n",
    " 'nlms': 'national longitudinal mortality study',\n",
    " 'nshd': 'national survey of health and development',\n",
    " 'rhsa': 'rural high school aspirations study',\n",
    " 'sodb': 'southern ocean database',\n",
    " 'clsa': \"canadian longitudinal study of aging\",\n",
    " 'tlsa': \"taiwan longitudinal study of aging\",\n",
    " 'plsa': 'polish longitudinal study of aging',\n",
    " 'brdis': 'business research development and innovation survey',\n",
    " 'woa/wod': 'world ocean atlas and world ocean database',\n",
    " 'hses': 'high school effectiveness study',\n",
    " 'nsdr': 'national survey of doctorate recipients',\n",
    " 'seels': 'special education elementary longitudinal study',\n",
    " 'decls': 'delaware early childhood longitudinal study',\n",
    " 'ecls-k': 'early childhood longitudinal study-kindergarten',\n",
    " 'ntps': 'national teacher principal survey',\n",
    " 'wls': 'wisconsin longitudinal study',\n",
    " 'arms': 'agricultural resource management survey'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_acronym(label):\n",
    "    if \"(\" in label.split()[-1]:\n",
    "        return \" \".join(label.split()[:-1])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_labels = [l.lower().strip() for l in df.dataset_label.unique()] + [clean_text(l).strip() for l in df.dataset_label.unique()]\n",
    "train_dataset_labels += [remove_acronym(l.lower().strip()) for l in df.dataset_label.unique()]\n",
    "train_dataset_labels += list(ACRONYM_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extra_labels = pd.read_csv(f\"{settings['RAW_DATA_DIR']}/extra_train_labels.csv\")[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_labels = list(set(train_dataset_labels + train_extra_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_extra_labels = pd.read_csv(f\"{settings['RAW_DATA_DIR']}/extra_valid_labels.csv\")[\"label\"].tolist()\n",
    "valid_extra_labels = [l.lower() for l in valid_extra_labels] + [clean_text(l).strip() for l in valid_extra_labels]\n",
    "valid_extra_labels = [l for l in valid_extra_labels if l not in all_train_labels] # just to be sure non-overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posible_labels = train_dataset_labels + train_extra_labels + valid_extra_labels\n",
    "all_posible_labels = list(set(all_posible_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_posible_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_pred_in_text(normed_text, all_unique_preds):\n",
    "    normed_text_lower = custom_clean_text(normed_text)\n",
    "    clean_normed_text_lower = clean_text(normed_text_lower).strip()\n",
    "    diff_len = abs(len(normed_text_lower) - len(normed_text))\n",
    "    preds = []\n",
    "    raw_preds = []\n",
    "    preds_indexs = []\n",
    "    for pred in all_unique_preds:\n",
    "        if len(pred.split(\" \")) <= 2:\n",
    "            if (\n",
    "                \" \" + pred + \" \" in normed_text_lower\n",
    "                or \" \" + pred + \".\" in normed_text_lower\n",
    "                or \" \" + pred + \",\" in normed_text_lower\n",
    "                or \" \" + pred + \";\" in normed_text_lower\n",
    "            ) and pred != \"\":\n",
    "                preds.append(pred)\n",
    "        else:\n",
    "            if pred in normed_text_lower:\n",
    "                preds.append(pred)\n",
    "\n",
    "    for pred in preds:\n",
    "        if len(pred.split(\" \")) <= 2:\n",
    "            start_index = normed_text_lower.index(\" \" + pred)\n",
    "            start_index += 1\n",
    "        else:\n",
    "            start_index = normed_text_lower.index(pred)\n",
    "\n",
    "        raw_pred = normed_text[start_index : start_index + len(pred)]\n",
    "        clean_raw_pred = clean_text(raw_pred).strip()\n",
    "        clean_pred = clean_text(pred).strip()\n",
    "\n",
    "        if clean_raw_pred != clean_pred:\n",
    "            # caused by lower()\n",
    "            found_true_label = False\n",
    "            for shift_index in range(-diff_len - 1, diff_len + 1):\n",
    "                raw_pred_candidate = normed_text[\n",
    "                    start_index + shift_index : start_index + shift_index + len(pred)\n",
    "                ]\n",
    "                clean_raw_pred_candidate = clean_text(raw_pred_candidate).strip()\n",
    "                if clean_raw_pred_candidate == clean_pred:\n",
    "                    if len(raw_pred_candidate.split(\" \")) <= 2:\n",
    "                        if raw_pred_candidate.islower() is False:\n",
    "                            preds_indexs.append(\n",
    "                                [\n",
    "                                    raw_pred_candidate,\n",
    "                                    [\n",
    "                                        start_index + shift_index,\n",
    "                                        start_index + shift_index + len(pred),\n",
    "                                    ],\n",
    "                                ]\n",
    "                            )\n",
    "                            raw_preds.append(raw_pred_candidate)\n",
    "                    else:\n",
    "                        preds_indexs.append(\n",
    "                            [\n",
    "                                raw_pred_candidate,\n",
    "                                [\n",
    "                                    start_index + shift_index,\n",
    "                                    start_index + shift_index + len(pred),\n",
    "                                ],\n",
    "                            ]\n",
    "                        )\n",
    "                        raw_preds.append(raw_pred_candidate)\n",
    "                    found_true_label = True\n",
    "                    break\n",
    "        else:\n",
    "            if len(raw_pred.split(\" \")) <= 2:\n",
    "                # acronym is not lower\n",
    "                if raw_pred.islower() is False:\n",
    "                    preds_indexs.append(\n",
    "                        [raw_pred, [start_index, start_index + len(pred)]]\n",
    "                    )\n",
    "                    raw_preds.append(raw_pred)\n",
    "            else:\n",
    "                preds_indexs.append([raw_pred, [start_index, start_index + len(pred)]])\n",
    "                raw_preds.append(raw_pred)\n",
    "\n",
    "    group_idxs = []\n",
    "    for i in range(len(preds_indexs)):\n",
    "        for j in range(len(preds_indexs)):\n",
    "            if i != j:\n",
    "                start_i, end_i = preds_indexs[i][1]\n",
    "                start_j, end_j = preds_indexs[j][1]\n",
    "                if start_i <= end_j and end_i <= end_j and start_i >= start_j:\n",
    "                    group_idxs.append([i, j])\n",
    "    raw_preds = np.array(raw_preds)\n",
    "    for group_idx in group_idxs:\n",
    "        raw_preds[group_idx[0]] = raw_preds[group_idx[1]]\n",
    "    return np.unique(raw_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "win_size = 200\n",
    "\n",
    "def process(i):\n",
    "    ids = []\n",
    "    titles = []\n",
    "    texts = []\n",
    "    raw_texts = []\n",
    "    labels = []\n",
    "    pub_titles = []\n",
    "    cleaned_labels = []\n",
    "    row = df.iloc[i]\n",
    "    x = json.load(open(f\"{settings['RAW_DATA_DIR']}/train/{row.Id}.json\",\"rt\"))\n",
    "    for section in x:\n",
    "        raw_text = section[\"text\"].replace(\"\\n\", \" \")\n",
    "        raw_text_encode = raw_text.split(\" \")\n",
    "        s_e = generate_s_e_window_sliding(len(raw_text_encode), win_size, int(0.75*win_size))\n",
    "        for (s, e) in s_e:\n",
    "            pub_titles.append(row.pub_title)\n",
    "            raw_sent = \" \".join(raw_text_encode[s:e]).strip()\n",
    "            titles.append(section[\"section_title\"])\n",
    "            ids.append(row.Id)\n",
    "            found_labels = find_all_pred_in_text(raw_sent, all_posible_labels)\n",
    "            if len(found_labels) > 0:\n",
    "                labels.append(\"|\".join(found_labels))\n",
    "            else:\n",
    "                labels.append(\"\")\n",
    "            texts.append(raw_sent)\n",
    "        \n",
    "    results = {}\n",
    "    results[\"id\"] = ids\n",
    "    results[\"pub_title\"] = pub_titles\n",
    "    results[\"title\"] = titles\n",
    "    results[\"text\"] = texts\n",
    "    results[\"label\"] = labels\n",
    "    return results\n",
    "\n",
    "results = pqdm(list(range(len(df))), process, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "titles = []\n",
    "texts = []\n",
    "labels = []\n",
    "pub_titles = []\n",
    "\n",
    "for result in tqdm(results):\n",
    "    ids.extend(result[\"id\"])\n",
    "    titles.extend(result[\"title\"])\n",
    "    texts.extend(result[\"text\"])\n",
    "    labels.extend(result[\"label\"])\n",
    "    pub_titles.extend(result[\"pub_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df[\"id\"] = ids\n",
    "train_df[\"pub_title\"] = pub_titles\n",
    "train_df[\"title\"] = titles\n",
    "train_df[\"text\"] = texts\n",
    "train_df[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"] = train_df[\"label\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(subset=None,\n",
    "                     keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_labels = train_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = []\n",
    "for tl in all_train_labels:\n",
    "    for l in tl.split(\"|\"):\n",
    "        if l.islower():\n",
    "            bad_labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = sorted(list(set(bad_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_labels = [\"Slosh\", \"aDNI\", \"Gels\", \"HSEs\", \"WLs\", \"iSDR\",\n",
    "                 \"ADni\", \"adnI\", \"Naep\", \"ECLs\", \"hSLS\", \"PeeLS\", \"pLSA\",\n",
    "                 \"Arms\", \"NTPs\", \"Billion-Ton-Study\", \"Plan-Do-Study-Act\", \"eCLS-B\"]\n",
    "ignore_labels.extend(bad_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ignore(data, ignore_labels):\n",
    "    for ig_label in ignore_labels:\n",
    "        data = data[data.label != ig_label]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_data_ignore(train_df, ignore_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = train_df.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_labels = []\n",
    "\n",
    "for org_label in tqdm(original_labels):\n",
    "    if org_label != \"\":\n",
    "        single_labels = org_label.split(\"|\")\n",
    "        valid_labels = list(set(single_labels) - set(ignore_labels))\n",
    "        re_labels.append(\"|\".join(valid_labels))\n",
    "    else:\n",
    "        re_labels.append(org_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.label = re_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_df.label != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df[train_df.label != \"\"].text.tolist()\n",
    "labels = train_df[train_df.label != \"\"].label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{settings['PROCESSED_DATA_DIR']}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will split all samples that >= 2 unique label for test set. (only positive samples)\n",
    "train_df[\"is_multiple_label\"] = train_df.label.apply(lambda x: \"|\" in x)\n",
    "train_df[train_df.is_multiple_label][train_df.columns[:-1]].to_csv(\n",
    "    f\"{settings['PROCESSED_DATA_DIR']}/test_positive_sampled.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df.is_multiple_label][train_df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_positive = train_df[train_df.label != \"\"]\n",
    "train_df_negative = train_df[train_df.label == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_negative[\"group\"] = [int(0)] * len(train_df_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 unique label is 1 group\n",
    "label_to_idx = {}\n",
    "label_to_idx[''] = int(0)\n",
    "all_groups = []\n",
    "all_groups.append('')\n",
    "idx = 1\n",
    "for k in all_posible_labels:\n",
    "    label_to_idx[k.strip()] = int(idx)\n",
    "    label_to_idx[clean_text(k).strip()] = int(idx)\n",
    "    idx += 1\n",
    "    all_groups.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_positive[\"group\"] = train_df_positive.label.parallel_apply(\n",
    "    lambda x: label_to_idx[clean_text(x).strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = []\n",
    "valid_labels.extend(valid_extra_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_groups = [label_to_idx[val_label] for val_label in valid_labels]\n",
    "len(val_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_split = train_df_positive[train_df_positive.group.isin(val_groups)]\n",
    "train_df_split = train_df_positive[~train_df_positive.group.isin(val_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_labels = []\n",
    "for i in tqdm(range(len(val_df_split))):\n",
    "    val_label = val_df_split.iloc[i].label.split(\"|\")\n",
    "    all_valid_labels.extend(val_label)\n",
    "\n",
    "all_train_labels = []\n",
    "for i in tqdm(range(len(train_df_split))):\n",
    "    train_label = train_df_split.iloc[i].label.split(\"|\")\n",
    "    all_train_labels.extend(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_labels = list(set(all_valid_labels) - set(['']))\n",
    "all_train_labels = list(set(all_train_labels) - set(['']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove train samples that include valid labels\n",
    "all_train_texts = train_df_split[\"text\"].parallel_apply(lambda x: clean_text(x)).tolist()\n",
    "def check_exist(text, labels):\n",
    "    for i in range(len(labels)):\n",
    "        l = clean_text(labels[i]).strip()\n",
    "        if (\" \" + l + \" \" in text or \" \" + l + \",\" in text or \" \" + l + \".\" in text or \" \" + l + \";\" in text):\n",
    "            return True\n",
    "    return False\n",
    "train_choosen_idxs = []\n",
    "for i, text in tqdm(enumerate(all_train_texts)):\n",
    "    exist = check_exist(text, all_valid_labels)\n",
    "    if exist is False:\n",
    "        train_choosen_idxs.append(i)\n",
    "train_df_split = train_df_split.iloc[train_choosen_idxs]\n",
    "len(train_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove val samples that include train labels\n",
    "all_val_texts = val_df_split[\"text\"].parallel_apply(lambda x: clean_text(x)).tolist()\n",
    "def check_exist(text, labels):\n",
    "    for i in range(len(labels)):\n",
    "        l = clean_text(labels[i]).strip()\n",
    "        if (\" \" + l + \" \" in text or \" \" + l + \",\" in text or \" \" + l + \".\" in text or \" \" + l + \";\" in text):\n",
    "            return True\n",
    "    return False\n",
    "val_choosen_idxs = []\n",
    "for i, text in tqdm(enumerate(all_val_texts)):\n",
    "    exist = check_exist(text, all_train_labels)\n",
    "    if exist is False:\n",
    "        val_choosen_idxs.append(i)\n",
    "val_df_split = val_df_split.iloc[val_choosen_idxs]\n",
    "len(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75 % negative samples for train, 25 % for validation\n",
    "train_df_negative_split = train_df_negative.sample(frac=0.75,random_state=200)\n",
    "val_df_negative_split = train_df_negative.drop(train_df_negative_split.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = pd.concat([train_df_split, train_df_negative_split])\n",
    "val_df_split = pd.concat([val_df_split, val_df_negative_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_labels = list(set(train_df_split.label.unique()) - set([\"\"]))\n",
    "all_valid_labels = list(set(val_df_split.label.unique()) - set([\"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_positive_df = pd.read_csv(f\"{settings['PROCESSED_DATA_DIR']}/test_positive_sampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_train(x):\n",
    "    all_single_labels = x.split(\"|\")\n",
    "    all_single_labels = [l.strip() for l in all_single_labels]\n",
    "    for l in all_single_labels:\n",
    "        if l not in all_train_labels:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_in_valid(x):\n",
    "    all_single_labels = x.split(\"|\")\n",
    "    all_single_labels = [l.strip() for l in all_single_labels]\n",
    "    for l in all_single_labels:\n",
    "        if l not in all_valid_labels:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_positive_df[\"in_train\"] = multiple_positive_df.label.apply(lambda x: is_in_train(x))\n",
    "multiple_positive_df[\"in_valid\"] = multiple_positive_df.label.apply(lambda x: is_in_valid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_positive_df_train = multiple_positive_df[multiple_positive_df.in_train==True]\n",
    "multiple_positive_df_valid = multiple_positive_df[multiple_positive_df.in_valid==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = pd.concat([train_df_split, multiple_positive_df_train])\n",
    "val_df_split = pd.concat([val_df_split, multiple_positive_df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = train_df_split[train_df_split.columns[:-2]].fillna(\"\")\n",
    "val_df_split = val_df_split[val_df_split.columns[:-2]].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_group(x):\n",
    "    # all samples that contain >= 2 labels is assigned\n",
    "    # as a group idx 10000\n",
    "    if x == \"\":\n",
    "        return 10000\n",
    "    else:\n",
    "        return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split[\"group\"] = train_df_split.group.apply(lambda x: replace_group(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_split[\"group\"] = val_df_split.group.apply(lambda x: replace_group(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df_split.to_csv(f\"{settings['PROCESSED_DATA_DIR']}/val_sampled.csv\",index=False)\n",
    "train_df_split[train_df_split.columns[:-1]].to_csv(\n",
    "    f\"{settings['PROCESSED_DATA_DIR']}/train_sampled.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
