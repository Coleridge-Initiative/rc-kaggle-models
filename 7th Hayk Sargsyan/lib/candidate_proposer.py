"""
This module implements the candidate generation process for the classification.
While the train and test candidates are handleed differently in this
implementation, there is no good reason to do it. The only reason it is done
this way is because of version mismatch of the grouping logic that was used
for the training and inference part. Due to lack of time I ended up using
the model trained on data generated by the earlier versions of the proposer.
"""

import json
import logging
from .schwartz_hearst import extract_abbreviation_definition_pairs
from .candidate_grouping_training import group_train_candidates
from .candidate_grouping_inference import group_test_candidates

log = logging.getLogger(__name__)


class CandidateProposer():
    """Base Class for Candidate Proposers"""

    def __init__(self, df, settings, titel_label_mapping):
        self.df = df  # The dataframe that contains the publication sentences
        self.titel_label_mapping = titel_label_mapping
        self.settings = settings
        self.ids = []
        self.group_fn = None

    def construct_abbreviation_definition_pairs(self, sentences, ids):
        """Uses the Schwart-Hearts algorithm for extracting the

        abbreviation-definition mappings
        """
        # First run: Keeps only the abbreviations that have more then 1 capital
        # letters
        log.info('Extracting the abbrreviation-definition mappings...')
        abb_def_pairs = extract_abbreviation_definition_pairs(sentences, ids)
        abbreviations = abb_def_pairs['abbreviations']
        existing_abbreviations = {abb.lower() for abb in abbreviations}

        # Second run: Includes also the variants of the abbreviations extracted
        # in the previous run where some of the letters are lower-case
        abb_def_pairs = extract_abbreviation_definition_pairs(
            sentences, ids, existing_abbreviations=existing_abbreviations
        )
        abbreviations = abb_def_pairs['abbreviations']
        masked_sentences = abb_def_pairs['sentences_candidates']
        id_abb_def_mappings = abb_def_pairs["ids_abbreviations"]

        return (abbreviations, masked_sentences, id_abb_def_mappings)

    def get_ids(self):
        raise NotImplementedError()

    def concatenate_all_sentences_ids(self):
        id_sentences = self.df.groupby('Id')['sentences'].agg(list)
        all_sentences = []
        all_ids = []
        for Id in self.ids:
            all_sentences.extend(id_sentences[Id][0])
            all_ids.extend([Id] * len(id_sentences[Id][0]))
        log.info(f'Number of extracted sentences: {len(all_sentences)}')

        return (all_sentences, all_ids)

    def generate_candidates(self):
        sentences, ids = self.concatenate_all_sentences_ids()
        abbrevs, masked_sents, id_abb_def_mappings = self.construct_abbreviation_definition_pairs(
            sentences, ids)
        groups = self.group_fn(abbrevs, masked_sents, self.titel_label_mapping)
        return (groups, id_abb_def_mappings)


class TrainCandidateProposer(CandidateProposer):
    """Candidate Proposer class for the training phase"""

    def __init__(self, df, settings, titel_label_mapping):
        super().__init__(df, settings, titel_label_mapping)
        self.ids = self.get_ids()
        self.group_fn = group_train_candidates

    def get_ids(self):
        """Get the order of ids that the publications will be processed"""

        # Ensures that the training data is processed in the correct order
        with open(self.settings['TRAIN_IDS'], 'r') as f:
            Ids = json.load(f)
        if set(Ids) == set(self.df['Id'].unique()):
            Ids = Ids
        else:
            Ids = list(self.df['Id'].unique())
        return Ids


class TestCandidateProposer(CandidateProposer):
    """Candidate Proposer class for the Inference phase"""

    def __init__(self, df, settings, titel_label_mapping):
        super().__init__(df, settings, titel_label_mapping)
        self.ids = self.get_ids()
        self.group_fn = group_test_candidates

    def get_ids(self):
        """Get the order of ids that the publications will be processed"""
        return list(self.df['Id'].unique())
